# -*- coding: utf-8 -*-
"""TP-datos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cIS9cFXRtDXCx1CANUsSSSPxUlPxwVtn
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from functools import lru_cache
import numpy as np

# %matplotlib inline
sns.set()

"""## Funciones auxiliares

### Funciones de carga y limpieza de datos
"""

@lru_cache()
def get_data(path):
    df = pd.read_csv(path)
    return df

def clean_df_column_names(df):
    df.columns = [(col.lower()
                      .rstrip()
                      .lstrip()
                      .replace(' ', '_')
                      .replace(',', '')
                      .replace('(', '')
                      .replace(')', ''))
                    for col in df.columns]
    return df

def clean_unused_columns(dataset, cols=None):
    cols_to_remove = ['prod_category_a',
                          'actual_delivery_date',
                          'asp_currency',  # Está en moneda local
                          'asp', # Está en moneda local
                          'last_activity',
                          'submitted_for_approval', # Llena de 0s
                          'sales_contract_no', # Revela el target, se explica 
                                               # en su correspondiente sección
                          'asp_converted_currency']
    if cols is not None:
        cols_to_remove = cols
    return dataset.drop(cols_to_remove, axis=1, errors='ignore')

def convert_columns_to_correct_format(df):
    df['planned_delivery_start_date'] = pd.to_datetime(df['planned_delivery_start_date'])
    df['planned_delivery_end_date'] = pd.to_datetime(df['planned_delivery_end_date'])
    df['account_created_date'] = pd.to_datetime(df['account_created_date'])
    df['price'] = pd.to_numeric(df['price'], errors='coerce')
    return df

"""## Funciones de estilos para gráficos"""

stages = {
  'Closed Lost': 0,
  'Closed Won': 1,
}
def get_palette(mode='rgb_p', category=None):
    palette = {
        'rgb_p': {
            0: (0.847, 0.106, 0.376),
            1: (0.118, 0.533, 0.898),
        },
        'hex': {
            0: '#D81B60',
            1: '#1E88E5',
        }
    }

    if category == None:
        return palette[mode]
    return palette[mode][category]

def get_palette_neutro(mode='rgb_p'):
    return get_palette(mode, 1)

def get_title_style(category=None):
    return {
        'fontdict': {
            'fontsize': 18,
            'fontweight': 2,
        },
        'pad': 10,
    }

"""#### Funciones útiles"""

def calculate_na_proportion(serie):
    return serie.isna().sum() / len(serie)

def flat_df_index(df):
    def __flat_col(col):
        if not all(col):
            return col[0]
        return '_'.join(col)
    df.columns = [
         __flat_col(col) for col in df.columns
    ]
    return df

"""#### Constantes"""

RANDOM_STATE = 22
np.random.seed(RANDOM_STATE)

"""## Formación del pipeline"""

imputers = set()
encoders = set()
models = set()

"""## Carga de datasets

Se carga el dataset para el entrenamiento.
"""

df = get_data('https://drive.google.com/u/0/uc?id=1asLtvBBNfILKC6totlZxO7Ax62eJ8q_I&export=download')
df = clean_df_column_names(df)
df.head().T

"""Se carga el dataset en el cual se harán las predicciones para la entrega en Kaggle"""

submit_df = get_data('https://drive.google.com/u/0/uc?id=1rzP5pmMnbSBEkjW6tvd9IMYGKbbuAJ7g&export=download')
submit_df = clean_df_column_names(submit_df)

"""## Observación: Sales Contract Number
Antes de seguir manipulando el dataset, desde la cátedra nos indicaron que hay una columna que delata el target, esta columna es `sales_contract_no`, es decir, aquellas oportunidades que tiene un número de contrato es porque son oportunidades ganadas. Tal como lo ilustra el siguiente gráfico.
"""

has_contract_no_vs_stage_won = df.groupby('opportunity_id').agg({
    'sales_contract_no': [('has_contract_no', lambda x: any(c != 'None' for c in x))],
    'stage': [('has_won', lambda x: any(c == 'Closed Won' for c in x))],
})
has_contract_no_vs_stage_won.columns = [col[1] for col in has_contract_no_vs_stage_won.columns]
has_contract_no_vs_stage_won = (has_contract_no_vs_stage_won
                                .reset_index()
                                .groupby(['has_contract_no', 'has_won'])['opportunity_id']
                                .count().unstack().reset_index())
has_contract_no_vs_stage_won.columns = ['Tiene número de contrato', 'Cant. perdidas', 'Cant. ganadas']
ax = has_contract_no_vs_stage_won.plot(x='Tiene número de contrato', y=['Cant. perdidas', 'Cant. ganadas'], 
                            kind='bar', figsize=(18, 5), rot=0, 
                            color=get_palette().values())
ax.set_ylabel('Cant. de oportunidades')
_ = ax.set_title('Tener número de contrato delata la probabilidad de éxito', **get_title_style())

"""Por esta razón, para utilizar cualquier modelo, esta variable será eliminada.

## Limpieza de datos
"""

df.head().T

df.info()

def data_type_convertion(data):
    data['account_created_date'] = pd.to_datetime(data.account_created_date, 
                                                  errors='coerce')
    data['opportunity_created_date'] = pd.to_datetime(data.opportunity_created_date, 
                                                      errors='coerce')
    data['price'] = pd.to_numeric(data.price, errors='coerce')
    data['planned_delivery_start_date'] = pd.to_datetime(data.planned_delivery_start_date, 
                                                         errors='coerce')
    data['planned_delivery_end_date'] = pd.to_datetime(data.planned_delivery_end_date, 
                                                       errors='coerce')
    return data

df = data_type_convertion(df)

df.describe().T

"""Se tienen 16947 registros en el df, con 52 columnas"""

df.shape

"""Pero se tienen 9841 oportunidades distintas"""

len(df.opportunity_id.unique())

"""### Reducción de posibles stages

Como lo que se quiere predecir es la probabilidad de éxito (oportunidad `Closed Won`), y hay un desbalance en la cantidad de oportunidades por tipo de `stage` (como se muestra en el gráfico), solamente se mantienen los casos `Closed Won` y `Closed Lost`.
"""

import math
data_stage_count = (
    df.stage.value_counts()
               .sort_values(ascending=False)
               .to_frame()
               .reset_index()
               .rename(columns={
                           'index': 'Stage', 
                           'stage': 'Cantidad'
                       }))
  
plt.figure(figsize=(10, 6))
ax = sns.barplot(x='Cantidad', y='Stage', 
                 data=data_stage_count, orient='h', 
                 palette=[get_palette_neutro()])
ax.set_title('Cantidad de oportunidades por Stage')
ax.set_xscale('log')
for index, row in data_stage_count.iterrows():
    ax.text(row['Cantidad'] * 1.2 , row.name, 
            round(row['Cantidad'], 2), 
            color='black', ha='left', 
            va='center')

"""Y reduciendo más la complejidad, se lo convierte a una variable binaria."""

def encode_target(data):
    data = data[data.stage.eq('Closed Won') | data.stage.eq('Closed Lost')].copy()
    data['stage'] = data.stage.eq('Closed Won').astype(int)
    return data

df = encode_target(df)

"""### Columnas con datos no relevantes

- `prod_category_a`
- `actual_delivery_date`
- `asp_currency`
- `asp`
- `last_activity`
- `submitted_for_approval`
- `sales_contract_no`
- `asp_converted_currency`

#### prod_category_a, actual_delivery_date, last_activity, submitted_for_approval, asp_converted_currency

Solo cuentan con una categoría y esta no brindan información alguna.
"""

df.prod_category_a.value_counts()

df.actual_delivery_date.value_counts()

df.last_activity.value_counts()

df.submitted_for_approval.value_counts()

df.asp_converted_currency.value_counts()

df.asp.value_counts()

df.asp_currency.value_counts()

"""#### asp_currency, asp
Como se puede ver en la siguiente tabla, la conversión entre el `asp` y `asp_converted` es prácticamente contante para todas las posibles monedas, es decir, la conversión se hizo en el mismo momento para todas las monedas. Por una cuestión de unicidad, se descarta el `asp` original y se conserva `asp_converted` que está en la misma moneda para todas las oportunidades. 
"""

def create_asp_ratio(data):
    df_filtered = data[['asp', 'asp_currency', 'asp_converted']].copy()
    df_filtered = df_filtered[~df_filtered.asp.isna() & ~df_filtered.asp_converted.isna()]
    data['asp_ratio'] = df_filtered.asp / df_filtered.asp_converted
    return data
df = create_asp_ratio(df)
df[['asp_currency', 'asp_ratio']].groupby('asp_currency').std()

"""##### Caso de Japón

Al parecer no está siguiendo la regla anterior. Aunque haya dado una desviación estándar mayor a las demás, por el siguiente gráfico, se puede ver que se mantiene una lineadidad.
"""

df_filtered_japan = df[df.asp_currency.eq('JPY')][['asp', 'asp_converted']]

fig, ax = plt.subplots()
fig.set_size_inches(11, 8)
_ = sns.scatterplot(data=df_filtered_japan, x='asp', y='asp_converted', ax=ax)

"""En conclusión, se pueden descartar las columnas `asp`, `asp_currency`, ya que no aportan información."""

df = clean_unused_columns(df)

df.head().T

opportunity_qty = len(df.opportunity_id.unique())
opportunity_qty

len(df.groupby(['opportunity_id']).groups.keys())

common_data_columns = [
    'opportunity_id', 
    'opportunity_name', 

    'source',
    'opportunity_owner',
    'opportunity_created_date',
    'opportunity_type',

    'last_modified_date',
    'last_modified_by',

    'bureaucratic_code',
    'bureaucratic_code_0_approved',
    'bureaucratic_code_0_approval',

    'pricing_delivery_terms_approved',
    'pricing_delivery_terms_quote_appr',


    'account_name',
    'account_owner',                       

    'account_type',
    'account_created_date',

    'quote_type',
    'quote_expiry_date',

    'delivery_terms',   
    'region', 
    'territory', 
    'billing_country',   

#     'price',
#     'currency',

# TODO: Si bien los siguientes son unique en las oportunidades
# ver si tiene sentido que estén en la data de oportunidad
    
#                          'brand',
#                          'product_type',
#                          'size',
#                          'product_category_b',
#                          'product_family',
#                          'product_name',


#                          'asp_converted',
#                          'planned_delivery_start_date',
#                          'planned_delivery_end_date',
#                          'delivery_quarter',   
#                          'month',                       
#                          'delivery_year', ~ No cambia mucho la cardinalidad (9855)
#                          'trf',

#     'total_amount_currency',
#     'total_amount',
    
    'total_taxable_amount',
    'total_taxable_amount_currency',
    
    'stage',
]
def group_data_by_opp_id(data, common_data_columns):
    return data.groupby(common_data_columns).groups.keys()

opportunity_common_data = group_data_by_opp_id(df, common_data_columns)
len(opportunity_common_data)

c = common_data_columns.copy()
c.remove('stage')
len(group_data_by_opp_id(submit_df, c))

1567

def create_opp_df(data, columns):
    return pd.DataFrame(data=data, columns=columns)

opp_df = create_opp_df(opportunity_common_data,
                       columns=common_data_columns)

opp_df.head().T

def create_sales_df(data, opp_columns):
    sales_df_columns = set(data.columns) - set(opp_columns)

    sales_df_columns = ['opportunity_id'] + list(sales_df_columns)
    if 'stage' in sales_df_columns:
        sales_df_columns.remove('stage')
    sales_df = data[sales_df_columns].copy()
    return clean_unused_columns(sales_df, ['id'])

sales_df = create_sales_df(df, common_data_columns)

sales_df.head().T

"""#### product_category_b
La gran mayoría ($\%93.96$) de los registros cuentan con valores nulos, con lo cual sacar conclusiones en base a `product_category_b`, no tendrá gran peso en la predicción. Se simplificará a `has_category_b` y más tarde se evaluará si tiene algún efecto en los modelos.
"""

product_category_b_counts = sales_df.product_category_b.value_counts()
percentage_category_none = product_category_b_counts['None'] /  product_category_b_counts.sum()
print(percentage_category_none)
product_category_b_counts

def create_has_category_b(data):
    data['has_category_b'] = data.product_category_b.ne('None').astype(int)
    return data

sales_df = create_has_category_b(sales_df)
sales_df = clean_unused_columns(sales_df, ['product_category_b'])

"""#### brand
La gran mayoría ($\%93.88$) de los registros cuentan con valores nulos, con lo cual sacar conclusiones en base a `brand`, no tendrá gran peso en la predicción. Se simplificará a `has_brand` y más tarde se evaluará si tiene algún efecto en los modelos.
"""

brand_counts = sales_df.brand.value_counts()
percentage_brand_none = brand_counts['None'] /  brand_counts.sum()
print(percentage_brand_none)
brand_counts

def create_has_brand(data):
    data['has_brand'] = data.brand.ne('None').astype(int)
    return data
sales_df = create_has_brand(sales_df)
sales_df = clean_unused_columns(sales_df, ['brand'])

"""#### product_family"""

family_counts = sales_df.product_family.value_counts()

# TODO: reducir la cardinalidad de product_family
register_per_family = sales_df.product_family.value_counts()
register_per_family = register_per_family[register_per_family > 100]
_ = (register_per_family).hist(bins=10)
print("Territorios distintos", len(register_per_family))

"""
    # Posibles features para las oportunidades
    - Cantidad de familias distintas  
    - Promedio de la cardinalidad de cada familia
    - Desviación de la cardinalidad de cada familia
"""
register_per_family

"""#### size
La gran mayoría ($\%94.19$) de los registros cuentan con valores nulos, con lo cual sacar conclusiones en base a `size`, no tendrá gran peso en la predicción. Se simplificará a `has_size` y más tarde se evaluará si tiene algún efecto en los modelos.
"""

size_counts = sales_df['size'].value_counts()
percentage_size_none = size_counts['None'] /  size_counts.sum()
print(percentage_size_none)
size_counts

def create_has_size(data):
    data['has_size'] = data['size'].ne('None').astype(int)
    return data
sales_df = create_has_size(sales_df)
sales_df = clean_unused_columns(sales_df, ['size'])

"""#### month, delivery_year, planned_delivery_start_date, planned_delivery_end_date
La columna se trata de un dato que no es átomico ya que contiene el mes y el año, probablemente el año está repitiendo data con `delivery_year`.
"""

sales_df[['year_from_month','month']] = sales_df.month.str.split('-',expand=True)

sales_df['year_from_month'] = sales_df.year_from_month.astype(int)
sales_df['month'] = sales_df.month.astype(int)

"""Como no hay ningún registro donde `year_from_month` (la columna recién creada) y `delivery_year` sean distintos, entonces contiene la misma data. Entonces, alguna de las dos será eliminada."""

sales_df[sales_df.year_from_month.ne(sales_df.delivery_year)]

"""Analogamente, pasa lo mismo con la información de `month` y `delivery_year`, con `planned_delivery_start_date`. Como este último con tiene la información del día, que puede llegar a ser útil, se eliminarán las primeras dos mencionadas."""

sales_df = clean_unused_columns(sales_df, ['year_from_month'])

sales_df['day_from_del_start'] = sales_df.planned_delivery_start_date.dt.day
sales_df['month_from_del_start'] = sales_df.planned_delivery_start_date.dt.month
sales_df['year_from_del_start'] = sales_df.planned_delivery_start_date.dt.year

sales_df[sales_df.year_from_del_start.ne(sales_df.delivery_year)]

sales_df[sales_df.month_from_del_start.ne(sales_df.month)]

sales_df = clean_unused_columns(sales_df, ['month', 'delivery_year',
                                           'day_from_del_start',
                                           'month_from_del_start',
                                           'year_from_del_start'])

sales_df.info()

"""#### product_name"""

register_per_name = sales_df.product_name.value_counts()
register_per_name_high = register_per_name[register_per_name > 50]
_ = (register_per_name_high).hist(bins=10)
print("Nombres distintos", len(register_per_name))
print("Total nombres no usados:", len(register_per_name) - len(register_per_name_high))

"""
    # Posibles features para las oportunidades
    - Cantidad de productos distintos (Puede que coincida con el count)  
    - Promedio de la cardinalidad de cada producto
    - Desviación de la cardinalidad de cada producto
    - Cantidad de veces que se vendió en dicha región
"""
register_per_name_high

"""#### planned_delivery_start_date, planned_delivery_end_date => planned_delivery_interval"""

def create_delivery_interval(data):
    planned_delivery_interval = (data.planned_delivery_end_date - 
                                 data.planned_delivery_start_date).dt.days
    data['planned_delivery_interval'] = planned_delivery_interval
    return data


sales_df = create_delivery_interval(sales_df)

_ = sales_df.planned_delivery_interval[sales_df.planned_delivery_interval.gt(0) & 
                                       sales_df.planned_delivery_interval.lt(200)].hist(bins=10)

"""Outlier: Un primer outlier fue encontrado, un registro cuya `planned_delivery_end_date` es `2208-12-31`, lo cual no tiene sentido en este ámbito. Al ser un solo caso, será descartado."""

sales_df[sales_df.planned_delivery_interval.gt(500)]

sales_df[sales_df.planned_delivery_interval.gt(2000)]
sales_df = sales_df.drop(sales_df.index[sales_df.planned_delivery_interval.gt(2000)])

sales_df.product_type.value_counts()

sales_df.head(20)

# TODO: reducir categorias < 200 -> other
sales_df.currency.value_counts()

opp_df[opp_df.opportunity_id.eq(9)].T

"""#### Aggregación de `sales` en `oportunidades`"""

def agregate_sales_to_opp(sales, opp):
    mean_per_opp = sales.groupby('opportunity_id').agg({
        'trf': [
            'mean', 
            'sum', 
            'count', 
        ],
        'planned_delivery_interval': [
            'mean', 
        ],
        'asp_ratio': [
            'mean'
        ],
        'total_amount': [
            'mean', # TODO: está dando malos resultados
            'sum', # TODO: está dando malos resultados
        ],
    }).reset_index()

    mean_per_opp = flat_df_index(mean_per_opp)
    opp = opp.merge(mean_per_opp, on='opportunity_id')
    return (sales, opp)

sales_df, opp_df = agregate_sales_to_opp(sales_df, opp_df)

opp_df.T

def create_amount_taxable_difference(df):
    df['amount_taxable_difference'] = df.total_amount_sum - df.total_taxable_amount
    return df

opp_df = create_amount_taxable_difference(opp_df)

amount_taxable_difference = opp_df.amount_taxable_difference

len(amount_taxable_difference[amount_taxable_difference.ne(0)])

opp_df[amount_taxable_difference.ne(0)].T

# TODO: reducir categorias < 200 -> other
opp_df.delivery_terms.value_counts()

opp_df.region.value_counts()

opp_df.quote_type.value_counts()

def create_quote_type_binding(data):
    data['quote_type_binding'] = data.quote_type.eq('Binding').astype(int)
    return data 
opp_df = create_quote_type_binding(opp_df)

# TODO: reducir categorias < 200 -> other
opp_df.account_type.value_counts()

# TODO: reducir categorias < 200 -> other
opp_df.bureaucratic_code.value_counts()

# TODO: reducir categorias < 1000 -> other
opp_df.source.value_counts()

# TODO: reducir categorias < 500 -> other
opp_df.opportunity_type.value_counts()

"""#### territory"""

# TODO: reducir la cardinalidad de territory
register_per_territory = df.territory.value_counts()
register_per_territory_lower = register_per_territory[register_per_territory < 200]
_ = register_per_territory[register_per_territory < 800].hist(bins=5)
print("Territorios distintos", len(register_per_territory_lower))
register_per_territory_lower

"""---

## Función auxiliar
Función auxiliar para manipular el dataset con los datos nuevos.
"""

def tune_dataset(data, common_opp_data_columns):
    data = data_type_convertion(data)
    data = create_asp_ratio(data)
    opp_shared_data = group_data_by_opp_id(data, common_opp_data_columns)
    opp_df = create_opp_df(opp_shared_data, common_opp_data_columns)
    sales_df = create_sales_df(data, common_opp_data_columns)
    sales_df = create_has_category_b(sales_df)
    sales_df = create_has_brand(sales_df)
    sales_df = create_has_size(sales_df)
    sales_df = create_delivery_interval(sales_df)

    opp_df = create_quote_type_binding(opp_df)
    
    sales_df, opp_df = agregate_sales_to_opp(sales_df, opp_df)
    opp_df = create_amount_taxable_difference(opp_df)
    
    return sales_df, opp_df

def create_submit_X_data(submit_df, common_data_columns, transformer, total_columns):
    submit_common_cols = common_data_columns.copy()
    submit_df = submit_df.copy()

    if 'stage' in submit_common_cols:
        submit_common_cols.remove('stage')
    
    sal, submit_opp_df = tune_dataset(submit_df, submit_common_cols)
    
    data = transformer.transform(submit_opp_df).todense()
    print(f"Sales qty: {len(sal)}")
    print(f"Opportunities qty: {len(submit_opp_df)}")
    
    return pd.DataFrame(data, columns=total_columns)

def test_over_submit_approximation(model, X_submit, X_train):    
    data = X_submit
    y_submit = submit_df.groupby('opportunity_id').first().sales_contract_no.ne('None').astype(int)
    show_model_stats(model, X_train, data, y_train, y_submit)

def prepare_submit(model, X_submit, name=''):
    data = X_submit
    y_hat = model.predict_proba(data)
    result = pd.concat([(submit_df.opportunity_id.to_frame()
                     .groupby('opportunity_id')
                     .first().reset_index()), 
           pd.Series(y_hat[:,1], name='target')], axis=1)
    if name:
        result.to_csv(f'/{name}.csv', index=False)
    return result

"""---"""

from sklearn.metrics import log_loss

from sklearn.metrics import plot_confusion_matrix

def show_model_stats(model, X_train, X_test, y_train, y_test):
    y_hat = model.predict_proba(X_test)
    print('log_loss test:', log_loss(y_test, y_hat))
    _ = plot_confusion_matrix(model, X_test, y_test, values_format='')

    print('Train score', model.score(X_train, y_train))
    print('Test score', model.score(X_test, y_test))

"""### Constantes"""

CHECK_FEATURE_IMPORTANCE = True

"""## Testeo primeros modelos

#### Primer modelo

##### Preparación de datos
"""

# first_iteration
columns_to_use_cat = [
    'bureaucratic_code',
    'account_type',
    'delivery_terms',
    'region',
]
columns_to_use_num = [
    'bureaucratic_code_0_approved',
    'bureaucratic_code_0_approval',
    'pricing_delivery_terms_approved',
    'pricing_delivery_terms_quote_appr',
    'quote_type_binding',
#     'price',
    'total_taxable_amount',
    'trf_mean',
    'trf_sum',
    'trf_count',
    'planned_delivery_interval_mean',
    'asp_ratio_mean',
    'total_amount_mean',
    'total_amount_sum',
    'amount_taxable_difference',
]

opp_df.head()

total_columns = columns_to_use_cat + columns_to_use_num
total_columns_s = pd.Series(total_columns)

"""### Transformaciones"""

from scipy import sparse

class BasicTransformer:
    def __init__(self, encoder, inputer, cat_cols, num_cols):
        self.encoder = encoder
        self.inputer = inputer
        self.cat_cols = cat_cols
        self.num_cols = num_cols
        
    def fit(self, data):
        self.encoder.fit(data[self.cat_cols])
        self.inputer.fit(data[self.num_cols])
        return self
        
    def transform(self, data):
        cat_data = self.encoder.transform(data[self.cat_cols])
        num_data = self.inputer.transform(data[self.num_cols])
        return sparse.hstack([cat_data, num_data])

from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder(handle_unknown='error')
encoders.add(enc)
enc

from sklearn.impute import SimpleImputer
imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
imputers.add(imp_mean)
imp_mean

transformer = BasicTransformer(enc, imp_mean, columns_to_use_cat, columns_to_use_num)

transformer.fit(opp_df)

cat_labels = list(enc.get_feature_names())

total_columns = cat_labels + columns_to_use_num

data_raw = transformer.transform(opp_df).todense()

data = pd.DataFrame(data_raw, columns=total_columns)

data.shape

corr_matrix = data.corr()

corr_matrix.shape

len(total_columns)

fig, ax = plt.subplots(figsize=(10, 9))
_ = sns.heatmap(corr_matrix, 
                xticklabels=total_columns,
                yticklabels=total_columns,
                cmap="YlGnBu",
                ax=ax)

_ = sns.heatmap(opp_df[columns_to_use_num].corr(), cmap="YlGnBu")

if CHECK_FEATURE_IMPORTANCE:
    total_columns = cat_labels + columns_to_use_num + ['random_value']
    data['random_value'] = np.random.rand(data.shape[0])
data.shape

target = opp_df.stage

"""### Spliteo de datos"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(data, target)

from sklearn.model_selection import GridSearchCV

"""## Modelos"""

models = {}

"""DecisonTree
---
"""

from sklearn.tree import DecisionTreeClassifier

tree = DecisionTreeClassifier(random_state=RANDOM_STATE)
"""
Best params:
    1st: max_depth=6, min_samples_split=20
    2nd: max_depth=6, min_samples_split=10
    3rd: max_depth=8, min_samples_split=8
    4th: max_depth=8, min_samples_split=9
"""
tree = GridSearchCV(tree, param_grid={
    'max_depth': [8, 10, 15],
    'min_samples_split': [8, 9, 10, 11],
})
tree.fit(X_train, y_train)
models['basic_des_tree'] = tree

tree.best_estimator_

tree.best_params_

"""
Con todos los features:
log_loss test: 0.8304249908211014
Train score 0.8232330110309138
Test score 0.7769607843137255
"""
show_model_stats(tree.best_estimator_, X_train, X_test, y_train, y_test)

tree.best_estimator_.tree_.max_depth

from sklearn.tree import plot_tree

fig, ax = plt.subplots(figsize=(25, 10))
_ = plot_tree(tree.best_estimator_, feature_names=total_columns,
              filled=True, rounded=True,
              max_depth=3, fontsize=12, ax=ax)

cols_feature_importance = tree.best_estimator_.feature_importances_
total_columns_s = pd.Series(total_columns)

most_important_features = None

if CHECK_FEATURE_IMPORTANCE:
    random_variable_importance = cols_feature_importance[-1]
    print('random variable importance:', random_variable_importance)
    print('columnas más importantes que la variable random:\n', 
          total_columns_s[cols_feature_importance > random_variable_importance])
    
    feature_importance_df  = pd.DataFrame({
        'feature_name': total_columns_s, 
        'feature_importance': cols_feature_importance
    }).sort_values('feature_importance').reset_index(drop=True)

    ax = (feature_importance_df
             .plot.barh(x='feature_name', figsize=(15, 10)))

    random_feature_row = (
        feature_importance_df[feature_importance_df
                                  .feature_name.eq('random_value')]
        .reset_index().iloc[0])
    
    index = random_feature_row[0]
    value = random_feature_row[-1]

    print(index, value)
    most_important_features = feature_importance_df[['feature_name', 'feature_importance']][index + 1:]
    print(most_important_features)
    _  = ax.barh([index], [value], color='r')
most_important_features

most_important_features = list(most_important_features.feature_name)

X_train

most_important_features = set(most_important_features)
most_important_features.add('x0_Bureaucratic_Code_2')
most_important_features.add('x0_Bureaucratic_Code_1')
most_important_features.add('x0_Bureaucratic_Code_0')
most_important_features.add('bureaucratic_code_0_approved')
most_important_features.add('x2_Delivery_Terms_2')
most_important_features.add('x2_Delivery_Terms_4')
most_important_features.add('x2_Delivery_Terms_6')
most_important_features.add('x2_Delivery_Terms_3')
most_important_features.add('x1_Account_Type_4')
most_important_features.add('x1_Account_Type_1')
most_important_features.add('x0_Bureaucratic_Code_6')
most_important_features.add('pricing_delivery_terms_approved')


for feature in total_columns:
  if feature in most_important_features:
    continue
  print()
  print('-'*40)
  print(feature)
  features = most_important_features.copy()
  features.add(feature)
  models['basic_des_tree'].fit(X_train[features], y_train)
  show_model_stats(models['basic_des_tree'].best_estimator_, 
                  X_train[features], 
                  X_test[features], 
                  y_train, y_test)

most_important_features

"""### DecisionTree usando ```most_important_features```

---
"""

tree = DecisionTreeClassifier(random_state=RANDOM_STATE)
"""
Best params:
    1st: max_depth=6, min_samples_split=20
    2nd: max_depth=6, min_samples_split=10
    3rd: max_depth=8, min_samples_split=8
    4th: max_depth=8, min_samples_split=9
"""
tree = GridSearchCV(tree, param_grid={
    'max_depth': [5, 7, 8],
    'min_samples_split': [8, 9, 10, 11],
})
tree.fit(X_train[most_important_features], y_train)
models['basic_des_tree'] = tree.best_estimator_
print(tree.best_params_)

show_model_stats(models['basic_des_tree'], X_train[most_important_features], 
                 X_test[most_important_features], y_train, y_test)

"""## Random Forest"""

from threading import Thread

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import RandomForestClassifier
# best_params = {
#     'bootstrap': False,
#     'max_features': 'auto',
#     'max_depth': 11,
#     'min_samples_leaf': 2,
#     'min_samples_split': 5,
#     'n_estimators': 1200,
# }
# clf_randforest = RandomForestClassifier(**best_params, 
#                                         random_state=RANDOM_STATE)
# """
# Best params:
# """
# 
# clf = GridSearchCV(clf_randforest, param_grid={
#     # 'bootstrap': [True, False],
#     # 'max_depth': [11, 12, 13],
#     # 'max_features': ['auto', 'sqrt'],
#     # 'min_samples_leaf': [1, 2, 3],
#     # 'min_samples_split': [2, 5, 7],
#     # 'n_estimators': [500, 1200, 2000],
# }, cv=3, n_jobs=-1)
# 
# clf.fit(X_train[most_important_features], y_train)
# models['random_forest_gs'] = clf
# print(clf.best_params_)

def run_random_forest_gs():
    models['random_forest_gs'].fit(X_train, y_train)
    print(models['random_forest_gs'].best_params_)
    
# Thread(target=run_random_forest_gs).start()

# run_random_forest_gs()



clf_randforest.fit(X_train[most_important_features], y_train)
models['random_forest'] = clf_randforest

show_model_stats(clf_randforest, X_train[most_important_features], 
                 X_test[most_important_features], y_train, y_test)

"""---

### XGBoost
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from xgboost import XGBClassifier
# best_params = {
#     'min_child_weight': 12,
#     'gamma': 1.5, 
#     'subsample': 0.9,
#     'colsample_bytree': 1.0,
#     'max_depth': 3,
# }
# 
# param_grid = {
#         # 'min_child_weight': [11, 12, 16],
#         # 'gamma': [0.5, 1, 1.5, 2, 5],
#         # 'subsample': [0.89, 0.9, 0.95],
#         # 'colsample_bytree': [0.99, 1.0],
#         'max_depth': [2, 3, 4, 5],
# }
# clf_XGB = XGBClassifier(**best_params, use_label_encoder=False, 
#                         eval_metric='logloss')
# 
# # bestParametersXGB
# clf_XGB_cv = GridSearchCV(clf_XGB, 
#                           param_grid=param_grid, 
#                           n_jobs=-1,
#                           cv=3)
# 
# # clf_XGB_cv.fit(X_train[most_important_features], y_train)
# # clf_XGB = clf_XGB_cv.best_estimator_
# # print(clf_XGB_cv.best_params_)
# # # models['random_forest_gs'] = clf

clf_XGB.fit(X_train[most_important_features], y_train)

show_model_stats(clf_XGB, X_train[most_important_features], 
                 X_test[most_important_features], y_train, y_test)

models['xgboost'] = clf_XGB

"""---

### LighGBM
"""

from lightgbm import LGBMClassifier

best_params = {
    'n_estimators': 75,
    'colsample_bytree': 0.55,
    'max_depth': 3,
    'num_leaves': 6,
    'reg_alpha': 1.3,
    'reg_lambda': 1.3,
    'min_split_gain': 0.4,
    'subsample': 0.86,
    'subsample_freq': 30,

}
param_grid = {
    # 'n_estimators': [70, 75, 80, 85],
    # 'colsample_bytree': [0.52, 0.55, 0.58, 0.65],
    # 'max_depth': [2, 3, 5],
    # 'num_leaves': [4, 5, 6, 7, 8],
    # 'reg_alpha': [1.25, 1.3, 1.35],
    # 'reg_lambda': [1.25, 1.3, 1.35],
    # 'min_split_gain': [0.35, 0.4, 0.45],
    # 'subsample': [0.85, 0.86, 0.87, 0.95, 0.9, 1],
    'subsample_freq': [20, 25, 30, 35],
}

clf_LGBM = LGBMClassifier(**best_params)

clf_LGBM = GridSearchCV(clf_LGBM,
                        param_grid=param_grid, 
                        cv=3, n_jobs=-1)

clf_LGBM.fit(X_train[most_important_features], y_train)
print(clf_LGBM.best_params_)

# models['random_forest_gs'] = clf

show_model_stats(clf_LGBM, X_train[most_important_features],
                 X_test[most_important_features], 
                 y_train, y_test)

models['lightgbm'] = clf_LGBM

"""### Bag Ensemble"""

from sklearn.ensemble import BaggingClassifier
# TODO: Aggregate on final model (with VotingClassifier)
bag_clf = (BaggingClassifier(tree.best_estimator_,
                             max_samples=0.5, max_features=0.5)
           .fit(X_train, y_train))
show_model_stats(bag_clf, X_train, X_test, y_train, y_test)

"""### AdaBoost"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# """
# # first_iteration
#  param_grid={
#     'n_estimators': [80, 100, 500],
# }
# best_param = {'n_estimators': 500}
# log_loss test: 0.6908309321790898
# Train score 0.7919106632166689
# Test score 0.7790032679738562
# n_jobs=8
# Wall time: 54.5 s
# 
# # second_iteration
# param_grid={
#     'n_estimators': [400, 500, 600],
# }
# best_params {'n_estimators': 600}
# log_loss test: 0.6911845348789579
# Train score 0.7920468473376004
# Test score 0.7785947712418301
# Wall time: 37.7 s
# 
# # third_iteration (scoring='neg_log_loss')
# Almost the same log_loss
# """
# from sklearn.ensemble import AdaBoostClassifier
# best_params = {
#     'n_estimators': 2100,
#     'learning_rate': 0.08,
# }
# model = AdaBoostClassifier(**best_params, 
#                            random_state=RANDOM_STATE)
# 
# # model = GridSearchCV(model, param_grid={
# #     'n_estimators': [2000, 2100, 2300],
# # }, n_jobs=-1, cv=3)
# 
# model.fit(X_train[most_important_features], y_train)
# # print("best_params", model.best_params_)
# # model = model.best_estimator_
# show_model_stats(model, X_train[most_important_features], 
#                  X_test[most_important_features], y_train, y_test)
# 
# models['adaboost'] = model

# cols_feature_importance = model.feature_importances_
# total_columns_s = pd.Series(total_columns)
# print(len(cols_feature_importance))

# if CHECK_FEATURE_IMPORTANCE:
#     random_variable_importance = cols_feature_importance[-1]
#     print('random variable importance:', random_variable_importance)
#     print('columnas más importantes que la variable random:', 
#           total_columns_s[cols_feature_importance > random_variable_importance])
#     feature_importance_df  = pd.DataFrame({
#         'feature_name': total_columns_s, 
#         'feature_importance': cols_feature_importance
#     }).sort_values('feature_importance').reset_index(drop=True)

#     ax = (feature_importance_df
#              .plot.barh(x='feature_name', figsize=(15, 10)))

#     random_feature_row = (
#         feature_importance_df[feature_importance_df
#                                   .feature_name.eq('random_value')]
#         .reset_index().iloc[0])
#     index = random_feature_row[0]
#     value = random_feature_row[-1]

#     print(index, value)
#     print(feature_importance_df[['feature_name', 'feature_importance']][index:])
#     _  = ax.barh([index], [value], color='r')
# model.feature_importances_

"""---

---

### Catboost test

Catboost toma significativamente más tiempo de entrenar que los modelos de sklearn, se requiere la utilización de ```n_jobs```, particularmente cuando se está realizando GridSearch.
"""

# %%time

# from catboost import CatBoostClassifier
# cat_features_cb = columns_to_use_cat
# all_features_cb = columns_to_use_cat + columns_to_use_num
# labels_cb = opp_df.stage
# X_train_cb, X_test_cb, y_train_cb, y_test_cb = train_test_split(opp_df[all_features_cb], labels_cb)
# model_cb = CatBoostClassifier(depth=11, iterations=80)
# """
# # first_iteration
# param_grid={
#     'iterations': [30, 50, 80],
#     'depth': [2, 5, 9, 15],
# }
# # second_iteration
# param_grid={
#     'iterations': [80, 90],
#     'depth': [7, 9, 11],
# }

# best_param = {'depth': 11, 'iterations': 80-}
# n_jobs=None
# Wall time: 4min 22s
# n_jobs=8

# Wall time: 1min 49s
# log_loss test: 0.4369047000924161
# Train score 0.8514231240637342
# Test score 0.7904411764705882
# """
# model_cb = GridSearchCV(model_cb, param_grid={
#     'iterations': [80, 100, 150],
#     'depth': [8, 9, 10],
# }, n_jobs=None)

# model_cb.fit(X_train_cb, y_train_cb, cat_features=cat_features_cb, 
#              verbose=False)
# print("best_params", model_cb.best_params_)
# model_cb = model_cb.best_estimator_
# final_model_cb = model_cb
# models['catboost'] = model_cb

# sorted(zip(all_features_cb, final_model_cb.get_feature_importance()), key=lambda x: -x[1])

# show_model_stats(final_model_cb, X_train_cb, X_test_cb, y_train_cb, y_test_cb)

# if 'stage' in common_data_columns:
#     common_data_columns.remove('stage')
# _, submit_opp_df_cb = tune_dataset(submit_df, common_data_columns)

# X_submit = submit_opp_df_cb[all_features_cb]
# test_over_submit_approximation(final_model_cb, X_submit, X_train_cb)

# result = prepare_submit(final_model_cb, X_submit, 'catboost-third-iteration')
# result.head()

"""---

## VotingClassifier Ensemble
"""

models

models_ = models.copy()
models_.pop('catboost', None)
models_.pop('random_forest_gs', None)
models_.pop('basic_des_tree', None)
models_.pop('adaboost', None)

for name, model in models_.items():
    print(f'model: {name}')
    model.fit(X_train[most_important_features], y_train)
    show_model_stats(model, 
                     X_train[most_important_features],
                     X_test[most_important_features],
                     y_train, y_test)

from sklearn.ensemble import VotingClassifier

vclf = VotingClassifier(estimators=list(models_.items()), voting='soft')

vclf.fit(X_train[most_important_features], y_train)

show_model_stats(vclf, X_train[most_important_features], 
                 X_test[most_important_features], 
                 y_train, y_test)

"""
Last submit:
Sales qty: 2551
Opportunities qty: 1567
log_loss test: 0.567005550638147
Train score 0.8512869399428027
Test score 0.7345245692405871
"""
total_columns_sub = total_columns.copy()
if 'random_value' in total_columns_sub:
  total_columns_sub.remove('random_value')
  
X_submit = create_submit_X_data(submit_df, common_data_columns, transformer, 
                                total_columns_sub)
test_over_submit_approximation(vclf, X_submit[most_important_features], 
                              X_train[most_important_features])
result = prepare_submit(vclf, X_submit[most_important_features], 'voting-ens_ada-rand-dec-xboost-ligh-most-important_features')

# result.head()

for name, model in models_.items():
  print()
  print('-'*40)
  print(f'model: {name}')
  test_over_submit_approximation(model, X_submit[most_important_features], 
                              X_train[most_important_features])

from sklearn.ensemble import BaggingClassifier
best_params = {
  'max_samples': 0.5,
  'max_features': 0.9,
}

bag_clf = BaggingClassifier(vclf,
                            **best_params,
                            random_state=RANDOM_STATE)
param_grid = {
    # 'max_samples': [0.4, 0.5, 0.6],
    'max_features': [0.7, 0.8,0.9],
}
# bag_clf_gs = GridSearchCV(bag_clf, param_grid=param_grid, 
#                           n_jobs=-1, cv=3)
# bag_clf_gs.fit(X_train[most_important_features], y_train)
# bag_clf_gs.best_params_

bag_clf.fit(X_train[most_important_features], y_train)
show_model_stats(bag_clf, 
                 X_train[most_important_features], 
                 X_test[most_important_features], 
                 y_train, 
                 y_test)

X_submit = create_submit_X_data(submit_df, common_data_columns, transformer, 
                                total_columns_sub)

test_over_submit_approximation(bag_clf,
                               X_submit[most_important_features], 
                               X_train[most_important_features])

result = prepare_submit(bag_clf, X_submit[most_important_features], 'final')
result.head()

"""### Estimación de target en test
Como `sales_contract_no` revela en gran parte el target, se lo calculara en el set de test para poder hacer pruebas locales.
"""

X_submit = create_submit_X_data(submit_df, common_data_columns, transformer, total_columns_sub)
test_over_submit_approximation(tree, X_submit[most_important_features], 
                               X_train[most_important_features])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# X_submit = create_submit_X_data(submit_df, common_data_columns, transformer)
# result = prepare_submit(tree, X_submit)
# result.head()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = models['random_forest']
# X_submit = create_submit_X_data(submit_df, common_data_columns, transformer, total_columns_sub)
# test_over_submit_approximation(model, X_submit[most_important_features], X_train[most_important_features])
# result = prepare_submit(model, X_submit[most_important_features], 'random-forest')
# 
# result.head()
#