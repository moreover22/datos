{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ParcialitoLSH.ipynb","provenance":[],"authorship_tag":"ABX9TyM8ciGm4jsxA6Im4ymObzR6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"56B9BM6NBjav"},"source":["### Hashing y LSH 2020-2C\n","\n","Contamos con una colección de 1300 millones de tweets con fake news. Queremos usarlos\n","para detectar otros tweets que puedan contener mensajes parecidos para poder filtrarlos.\n","\n","El objetivo final de nuestra aplicación es dado un tweet buscar cuáles son tweets parecidos en\n","nuestra base de 1300 millones de tweets usando LSH para luego decidir si el tweet es o no un\n","fake news. Si hay tweets muy similares al nuevo en nuestra base de datos, lo categorizamos\n","como fake news; caso contrario, no. El criterio que fijamos es que si el tweet actual tiene una\n","__semejanza mayor o igual a 0.73__ con alguno de nuestra base de fake news entonces es un fake\n","news.\n","\n","Se decide usar la __distancia de Jaccard__ como métrica para la construcción de nuestro __esquema\n","de LSH__.\n","\n","Queremos que si la __semejanza entre tweets es mayor o igual a 0.55__ tengamos __más de un 70%\n","de probabilidad de que sean candidatos__. Por otro lado, si la semejanza es __menor o igual a 0.05__\n","queremos tener __menos de un 1% de probabilidad de que sean candidatos__ a ser comparados.\n","\n","\n","En base a esta información le pedimos que responda las siguientes preguntas:\n","\n","1. ¿Cuántos minhash hacen falta y con qué tipo de esquema (b y r) ? Detalle los cálculos\n","realizados y estime cantidad de falsos positivos y falsos negativos que vamos a tener\n","sobre una base de 10000 tweets nuevos. (30 puntos)\n","\n","2. Describa la etapa de pre-procesamiento en la cual tiene que recorrer los 1300 millones\n","de tweets y crear una única tabla de hash. Recuerde que puede usar diagramas,\n","esquemas y pseudocódigo para hacer más clara su explicación. Debe ser claro\n","indicando cómo queda conformado el esquema LSH que va a usar en el punto 3. (35\n","puntos)\n","\n","3. Describir cómo se hace la predicción de si un tweet es fake news o no utilizando el\n","esquema LSH propuesto. (35 puntos)"]},{"cell_type":"markdown","metadata":{"id":"hqwBGDK7CY7k"},"source":["#### Ejercicio 1 \n","\n","¿Cuántos minhash hacen falta y con qué tipo de esquema (b y r) ? Detalle los cálculos realizados y estime cantidad de falsos positivos y falsos negativos que vamos a tener sobre una base de 10000 tweets nuevos. (30 puntos)\n","\n","----\n","\n","Se parte de que si la semejanza entre dos tweets, es decir $\\mathcal{J}(T_1, T_2) \\geq 0.55 = d_1$ la probabilidad de colisión tiene que ser $\\mathbb{P}(\"Colision\") \\geq 0.7 = p_1$, cuando $\\mathcal{J}(T_1, T_2) \\leq 0.05 = d_2$, queremos evitarlos con una probabilidad $\\mathbb{P}(\"Colision\") \\leq 0.01 = p_2$.\n","\n","Como $\\mathbb{P}(\"Colision\") = 1 - (1 - d^r)^b $\n","\n","De la primer restricción se consigue:\n","\n","$\\mathbb{P}(\"Colision\") = 1 - (1 - 0.55^r)^b \\geq 0.7$\n","\n","Y de la segunda:\n","\n","$\\mathbb{P}(\"Colision\") = 1 - (1 - 0.05^r)^b \\leq 0.01$\n","\n","Para encontrar los valores que satisfacen estas condiciones se realizará $\\verb|gridsearch|$\n","\n","|  $r$ | $b$ |$p_1$|$p_2$|\n","|----|----|---|---|\n","|2|2|0.5134|0.0004|\n","|2|3|0.6606|0.0007|\n","|2|4|0.7633|0.01|\n","\n","De lo que se concluye que $b = 4$ ($\\verb|or|$) y $r = 2 $ ($\\verb|and|$)\n","\n","\n","Los falsos positivos serán aquellos que fueron recuperados en la consulta pero que originalmente no eran deseados, es decir:\n","\n","$\\mathbb{P}(\"F^+\") = 1 - p_1 = 1 - 0.7633 = 0.2367$\n","\n","Por otro lado, los falsos negativos, son aquellos que se deberían haber recuperado en una consulta, pero que no lo hicieron (este tipo de error es más crítico):\n","\n","$\\mathbb{P}(\"F^-\") = p_2 = 0.01$\n","\n","Con lo cual estimando en el set completo de 10000:\n","\n","$|F^+| \\approx 10000 * 0.2367 = 2367$\n","\n","$|F^-| \\approx 10000 * 0.01 = 100$\n"]},{"cell_type":"markdown","metadata":{"id":"VkHxSLrhIMYQ"},"source":["#### Ejercicio 2\n","\n","Describa la etapa de pre-procesamiento en la cual tiene que recorrer los 1300 millones de tweets y crear una única tabla de hash. Recuerde que puede usar diagramas, esquemas y pseudocódigo para hacer más clara su explicación. Debe ser claro indicando cómo queda conformado el esquema LSH que va a usar en el punto 3. (35 puntos)\n","\n","----\n","Como pre-procesamiento de los datos, se tomará cada twit, se desompondrá en shingles, en un principio de longitud 2 (dando así $26^2$ posibilidades de shingles), por cada twit se ejecuta la siguiente función de $\\verb|minhash|$:\n","\n","$mh_i(T) = \\min_{s \\in shingles(T)}\\{ h_i(s) \\}$\n","\n","Habrá tantas $mh_i$ y por consiguiente $h_i$ como $r$, en el caso de que se decida hashear el shingle como una cadena se puede utilizar una función de hashing universal para input fijo, por ejemplo\n","``` python\n","def fixedlen_hash(a, p, m):\n","  return lambda x: sum((a[i] * el) % p for i, el in enumerate(x)) % m\n","```\n","\n","O bien, identificar cada shingle por un índice y hashearlo con una función de hash más simple (también universal):\n","\n","``` python\n","def numeric_hashing(a, b, p, m):\n","  return lambda x: ((a * x + b) % p) % m\n","```\n","\n","Por cada función de minhash y cada tweet se obtiene un valor, formando la tabla:\n","\n","|  $mh_i$ | T<sub>0</sub> |T<sub>1</sub>|T<sub>3</sub>|\n","|----|----|---|---|\n","|$mh_1$|2|1|2|\n","|$mh_2$|1|2|0|\n","|$mh_3$|1|1|1|\n","|$mh_4$|0|1|0|\n","|$mh_5$|1|1|1|\n","|$mh_6$|1|1|0|\n","|$mh_7$|3|3|1|\n","|$mh_8$|2|3|1|\n","\n","Tendría que haber $r * b = 4 * 2 = 8$ funciones de minhash(que se cumple), para luego ser mapeada a $b = 4$ bandas.\n","Una posible distribucíon:\n","\n","|  $mh_i$ | T<sub>0</sub> |T<sub>1</sub>|T<sub>2</sub>|\n","|----|----|---|---|\n","|$mh_1$|2|1|2|\n","|$mh_2$|1|2|0|\n","|----|----|---|---|\n","|$mh_3$|1|1|1|\n","|$mh_4$|0|1|0|\n","|----|----|---|---|\n","|$mh_5$|1|1|1|\n","|$mh_6$|1|1|0|\n","|----|----|---|---|\n","|$mh_7$|3|3|1|\n","|$mh_8$|2|3|1|\n","\n","\n","Por cada banda se distribuián los twits:\n","\n","| banda 1 ||\n","|----|----|\n","|0|$\\{ T_2 \\}$|\n","|1|$\\{ T_0, T_1 \\}$|\n","|2|$\\{ T_0, T_1, T_2 \\}$|\n","|3||\n","\n","<br>\n","\n","| banda 2 ||\n","|----|----|\n","|0|$\\{ T_0, T_2 \\}$|\n","|1|$\\{ T_0, T_1, T_2 \\}$|\n","|2||\n","|3||\n","<br>\n","\n","| banda 3 ||\n","|----|----|\n","|0|$\\{ T_0, T_1 \\}$|\n","|1|$\\{ T_0, T_1, T_2 \\}$|\n","|2||\n","|3||\n","\n","<br>\n","\n","| banda 4 ||\n","|----|----|\n","|0||\n","|1|$\\{ T_2 \\}$|\n","|2|$\\{ T_0\\}$|\n","|3|$\\{ T_0, T_1 \\}$|\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lMXEoxNEMLZm"},"source":["#### Ejercicio 3\n","Describir cómo se hace la predicción de si un tweet es fake news o no utilizando el esquema LSH propuesto. (35 puntos)\n","\n","----\n","\n","Dado un twit nuevo, se procede a descomponerlo en shingles tal como se hizo con los primeros, se calculan las distantas funciones de $\\verb|minhash|$ (por una cuestión de claridad lo agrego a las tablas anteriores):\n","\n","\n","|  $mh_i$ | T<sub>0</sub> |T<sub>1</sub>|T<sub>2</sub>|T<sub>3</sub><sup>$Q$</sup>|\n","|----|----|---|---|---|\n","|$mh_1$|2|1|2|**1**|\n","|$mh_2$|1|2|0|**0**|\n","|----|----|---|---|---|\n","|$mh_3$|1|1|1|**0**|\n","|$mh_4$|0|1|0|**1**|\n","|----|----|---|---|---|\n","|$mh_5$|1|1|1|**0**|\n","|$mh_6$|1|1|0|**3**|\n","|----|----|---|---|---|\n","|$mh_7$|3|3|1|**2**|\n","|$mh_8$|2|3|1|**3**|\n","\n","Ahora por cada franja se procede a recuperar los twees obteniendo así de cada banda:\n","\n","| banda 1 ||\n","|----|----|\n","|0|$\\{ T_2 \\}$|\n","|1|$\\{ T_0, T_1 \\}$|\n","|2|$\\{ T_0, T_1, T_2 \\}$|\n","|3||\n","\n","$$P_{B_1} = \\{T_2\\} \\cap \\{T_0, T_1\\} = \\{\\}$$\n","<br>\n","\n","| banda 2 ||\n","|----|----|\n","|0|$\\{ T_0, T_2 \\}$|\n","|1|$\\{ T_0, T_1, T_2 \\}$|\n","|2||\n","|3||\n","\n","$$P_{B_2} = \\{ T_0, T_2 \\} \\cap \\{ T_0, T_1, T_2 \\} = \\{ T_0, T_2 \\}$$\n","\n","<br>\n","\n","| banda 3 ||\n","|----|----|\n","|0|$\\{ T_0, T_1 \\}$|\n","|1|$\\{ T_0, T_1, T_2 \\}$|\n","|2||\n","|3||\n","\n","$$P_{B_3} = \\{ T_0, T_1 \\} \\cap \\{  \\} = \\{\\}$$\n","\n","<br>\n","\n","| banda 4 ||\n","|----|----|\n","|0||\n","|1|$\\{ T_2 \\}$|\n","|2|$\\{ T_0\\}$|\n","|3|$\\{ T_0, T_1 \\}$|\n","\n","$$P_{B_4} = \\{ T_0 \\} \\cap \\{ T_0, T_1  \\} = \\{T_0\\}$$\n","\n","\n","Finalmente ejecutando la etapa $\\verb|or|$:\n","\n","$P_{T_3} = P_{B_1} \\cup P_{B_2} \\cup P_{B_3} \\cup P_{B_4}$\n","\n","$P_{T_3} = \\{\\} \\cup \\{ T_0, T_2 \\} \\cup \\{\\} \\cup \\{T_0\\} $\n","\n","$P_{T_3} = \\{ T_0, T_2 \\}$\n","\n","Bastaría ahora hacer:\n","\n","```python\n","\n","similars_to_t_3 = {t_0, t_2}\n","result = []\n","for tweet in similars_to_t_3:\n","  if jacard_dist(tweet, t_3) > 0.73:\n","    result.append(tweet)\n","```\n","\n","Si bien, finalmente se realizan comparaciones, no se hacen sobre el set completo, si no, sobre un subconjunto de este, que es deseable que sea lo más chico posible tratando de no introducir muchos falsos negativos."]}]}